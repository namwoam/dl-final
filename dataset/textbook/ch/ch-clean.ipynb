{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning for chinese continuous-pretraining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitignore', '1-01.pdf', '1-02.pdf', '1-03.pdf', '1-04.pdf', '1-05.pdf', '1-06.pdf', '1-07.pdf', '1-08.pdf', '1-09.pdf', '1-10.pdf', '1-11.pdf', '1-12.pdf', '1-13.pdf', '1-14.pdf', '1-15.pdf', '2-01.pdf', '2-02.pdf', '2-03.pdf', '2-04.pdf', '2-05.pdf', '2-06.pdf', '2-07.pdf', '2-08.pdf', '2-09.pdf', '2-10.pdf', '2-11.pdf', '2-12.pdf', '2-13.pdf', '2-14.pdf', '2-15.pdf', '3-01.pdf', '3-02.pdf', '3-03.pdf', '3-04.pdf', '3-05.pdf', '3-06.pdf', '3-07.pdf', '3-08.pdf', '3-09.pdf', '3-10.pdf', '3-11.pdf', '3-12.pdf', '3-13.pdf', '4-01.pdf', '4-02.pdf', '4-03.pdf', '4-04.pdf', '4-05.pdf', '4-06.pdf', '4-07.pdf', '4-08.pdf', '4-09.pdf', '4-10.pdf', '4-11.pdf', '4-12.pdf', '4-13.pdf', '4-14.pdf', '4-15.pdf', '4-16.pdf', '5-01.pdf', '5-02.pdf', '5-03.pdf', '5-04.pdf', '5-05.pdf', '5-06.pdf', '5-07.pdf', '5-08.pdf', '5-09.pdf', '5-10.pdf', '5-11.pdf', '5-12.pdf', 'ch-clean.ipynb']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f for f in listdir(\"./\") if isfile(join(\"./\", f))]\n",
    "files = sorted(files)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing book2: 100%|██████████| 73/73 [00:02<00:00, 30.01it/s]\n",
      "Processing book3: 100%|██████████| 73/73 [00:04<00:00, 18.04it/s]\n",
      "Processing book4: 100%|██████████| 73/73 [00:02<00:00, 29.27it/s] \n",
      "Processing book5: 100%|██████████| 73/73 [00:02<00:00, 26.05it/s] \n",
      "Processing book6: 100%|██████████| 73/73 [00:05<00:00, 14.32it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "from tika import parser\n",
    "import tika\n",
    "tika.initVM()\n",
    "\n",
    "\n",
    "\n",
    "for index in range(1,6):\n",
    "    \n",
    "    book_content = []\n",
    "    for filename in tqdm(files, desc=f\"Processing book{index+1}\"):\n",
    "        if not filename.endswith(\".pdf\") or not filename.startswith(str(index)):\n",
    "            continue\n",
    "        parsed = parser.from_file(filename)\n",
    "        text = parsed[\"content\"]\n",
    "        text = text.replace(\"�\", \"\")\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        text = text.replace(\"　\", \"\")\n",
    "        text = text.replace(\"\u0001\", \"\")\n",
    "        text = text.replace(\" \", \"\")\n",
    "        text = text.replace(\"﹂\", \"\")\n",
    "        text = text.replace(\"﹁\", \"\")\n",
    "        text = text.replace(\"︶\", \"\")\n",
    "        text = text.replace(\"︵\", \"\")\n",
    "        text = text.replace(\"︻\", \"\")\n",
    "        text = text.replace(\"︼\", \"\")\n",
    "        book_content.append(text)\n",
    "    with open(f\"{index}.txt\", \"w+\") as writer:\n",
    "        writer.write(\"\\n\".join(book_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
